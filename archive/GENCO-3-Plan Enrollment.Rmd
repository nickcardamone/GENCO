---
title: "GENCO-3-Plan Enrollment"
author: "Nicholas Cardamone"
date: "10/8/2024"
output: html_document
---

# Goals: Webscrape plan enrollment by month files, then download formulary-plan-period files to crosswalk enrollment to prior auth by formulary Medicare Part D dataset from Part 2. Aggregate a dataset with prior auth of plans by application number by period with plan enrollment numbers.

# What this code does:
1. Download formulary by plan by period files from Dropbox - save to a directory folder called "plan".

2. Combine all formulary by plan by period files into one dataframe.

3. Webscrape plan enrollment by month data from CMS website.

4. Combine all monthly plan enrollment files into one dataframe, summarize by January - June / July - December.

5. Extract and monthly enrollment data 2007-2003 and aggregate to 6-month periods (plan level) by taking the average monthly enrollment
proportion (among all plans) for a plan by period (i.e. in period X, Plan A has 100 people but there are 400 enrollees across all plans, then Plan A receives a weight of 0.25). 

5. Join enrollment data to plan-formulary crosswalk dataset at 6-month period. Now that enrollment data is now organized at the formulary level with the sum enrollment weight (e.g. formulary is covered by Plan A and Plan C which have 25% and 14% of all monthly enrollees for period X, so 39% of all average monthly enrollees).

6. Join formulary-level enrollment data to formulary-level prior authorization data. The data is now organized as ingredient > application number (branded/generic) > RxCUI > NDC > formulary > period.

7. Create a “conversion date” variable – the period at which NDCs associated with a generic application number appear in 10% of the formularies this basket of generic NDCs is ever going to appear in.


```{r setup, include=FALSE}
library(rdrop2) # install_github("karthik/rdrop2") - use to connect to dropbox
library(httr) # webscraping 
library(stringr) # string manipulation
library(lubridate) # date manipualtion
library(haven) # webscraping
library(dplyr) # data wrangling
library(readr) # reading in different data types
library(tools) # utility 
library(devtools) # utility
```

```{r, Search Dropbox for relevant files}
# Define the root folder path in Dropbox
root_folder_path <- "GENCO"
drop_acc() %>% data.frame()
#drop_acc() %>% data.frame()
# List all folders and files in the root folder
all_files <- drop_dir(root_folder_path, dtoken= token)
# Filter for .dta files that start with "basic drugs formulary"
x <- drop_search("^plan information")
```
```{r, Download relevant files locally}
# Create the download function with checks for existing files
download_function <- function(match_item) {
  # Define the local path where the file will be downloaded
  local_file_path <- file.path("C://Users//Nick//Desktop//VA//GENCO//plan", basename(match_item$metadata$path_lower))
  
  # Check if the file already exists
  if (!file.exists(local_file_path)) {
    # Try downloading the file, handle any potential errors
    tryCatch({
      drop_download(match_item$metadata$path_lower, local_path = local_file_path, overwrite = TRUE)
      cat("Downloaded:", local_file_path, "\n")
    }, error = function(e) {
      cat("Error downloading", match_item$metadata$path_lower, ":", e$message, "\n")
    })
  } else {
    cat("File already exists, skipping download:", local_file_path, "\n")
  }
}

# Apply the function to each element in the list using lapply
lapply(x$matches, download_function)
```

```{r, Process Plan - Formulary Crosswalk Data Files}
# Define the path to the folder containing the .dta, .txt, and .zip files
folder_path <- "C://Users//Nick//Desktop//VA//GENCO//plan"

# List all .dta, .txt, and .zip files in the folder that end with "with drug names"
all_files <- list.files(folder_path, pattern = ".(dta|txt|zip)$", full.names = TRUE)

# Process the list of drug files and extract dates
names_df <- data.frame(
  name = basename(all_files)
) %>%
  mutate(
    date = case_when(
      # Extract exact date in YYYYMMDD format
      str_detect(name, "\\d{8}") ~ str_extract(name, "\\d{8}"),
      
      # If the name contains a format like YYYY-12, convert it to YYYY1231
      str_detect(name, "\\d{4}-12") ~ str_replace(str_extract(name, "\\d{4}-12"), "-12", "1231"),
      
      # If no date is found, extract the year and append 0630
      str_detect(name, "\\d{4}") ~ paste0(str_extract(name, "\\d{4}"), "0630"),
      
      # Default NA if no date or year is found
      TRUE ~ NA_character_
    )
  )

# Function to process each file based on the extracted date, with a sample of 50 observations
process_file <- function(file_path, date_var) {
  # Print the name of the file being processed
  cat("Processing file:", basename(file_path), "\n")
  
  # Detect the file extension
  file_extension <- file_ext(file_path)
  
  # Unzip if the file is a .zip and get the contained .txt file
  if (file_extension == "zip") {
    temp_dir <- tempdir()
    unzip(file_path, exdir = temp_dir)
    txt_files <- list.files(temp_dir, pattern = "\\.txt$", full.names = TRUE)
    
    if (length(txt_files) == 0) {
      stop("No .txt file found in the zip archive")
    }
    
    file_path <- txt_files[1]  # Assuming you want to process the first .txt file found
    file_extension <- "txt"  # Update the extension to .txt for further processing
  }
  
  # Read the file based on its extension
  if (file_extension == "dta") {
    data <- read_dta(file_path)
  } else if (file_extension == "txt") {
    # Adjusting to read the specified headers
    data <- read_delim(file_path, delim = "|", col_types = cols(), 
                       col_names = c("CONTRACT_ID", "PLAN_ID", "SEGMENT_ID", "CONTRACT_NAME", "PLAN_NAME", 
                                     "FORMULARY_ID", "PREMIUM", "DEDUCTIBLE", "ICL", "MA_REGION_CODE", 
                                     "PDP_REGION_CODE", "STATE", "COUNTY_CODE", "SNP"))  
  } else {
    stop("Unsupported file type")
  }
  
  # Convert all column names to lowercase for consistency
  names(data) <- tolower(names(data))
  
  # Ensure consistent data types
  data <- data %>%
    mutate(
      plan_id = as.character(plan_id),
      formulary_id = as.character(formulary_id),
      premium = as.character(premium),
      deductible = as.character(deductible),
      segment_id = as.character(segment_id),
      snp = as.character(snp),
      icl = as.character(icl)
    )
  
  # Convert the date string to Date type
  date_var <- as.Date(date_var, format = "%Y%m%d")
  
  # Select the required columns and add the "date" column
  data_selected <- data %>%
    select(contract_id, plan_id, segment_id, contract_name, plan_name, formulary_id, premium, deductible, icl,
           ma_region_code, pdp_region_code, state, county_code, snp) %>%
    mutate(date = date_var)
  
  return(data_selected)
}

```

```{r, Run function on all plan files and combine}
# Apply the function to all files and combine the results into one data frame

combined_plan_data <- mapply(
  process_file, 
  all_files, 
  names_df$date, 
  SIMPLIFY = FALSE
) %>% bind_rows()
```

```{r, Clean Plan Data}
# Importantly - pad the plan_id with 0s to eventually join it to formulary-level data.
combined_plan_data <- combined_plan_data %>% select(contract_id, plan_id, formulary_id, segment_id, date) %>% mutate(plan_id = str_pad(plan_id, 3, pad = "0")) %>% distinct()

```

```{r, Save Plan-Formulary File Locally}
write.csv(combined_plan_data, "C://Users//Nick//Desktop//VA//GENCO-Misc//combined_plan_data_n=134198-10-31-2024.csv")

```

```{r, Load Plan-Formulary Data}
combined_plan_data <- read.csv("C://Users//Nick//Desktop//VA//GENCO-Misc//combined_plan_data_n=134198-10-31-2024.csv")

```

```{r, Clean Plan-Formulary Data}
combined_plan_data <- combined_plan_data %>% filter(segment_id != "SEGMENT_ID")
combined_plan_data$segment_id <- as.factor(as.numeric(combined_plan_data$segment_id))
combined_plan_data$plan_id <- as.factor(as.numeric(combined_plan_data$plan_id))

combined_plan_data <- combined_plan_data %>% select(formulary_id, contract_id, plan_id, segment_id, date) %>% group_by(formulary_id, contract_id, plan_id, segment_id, date)
```

## Webscraping enrollment data:
# 1.) Webscrape all links from list of monthly enrollment number webpages.
# 2.) Open all such links and click the hyperlink to download the respective zip file.
# 3.) Manually unzip all the .txt files using 7-ZIP.
# 4.) Read .txt files and combine like we do above.

```{r, Webscrape  Enrollment Data}
## Give me R
# Step 1: Read the main page and extract the links from the table
main_url <- "https://www.cms.gov/data-research/statistics-trends-and-reports/medicare-advantagepart-d-contract-and-enrollment-data/monthly-enrollment-plan"  # Replace with the URL of the main page

# Read the HTML of the main page
main_page <- read_html(main_url, user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3")

# Extract all the links in the table
links <- main_page %>%
  html_nodes("table a") %>%  # Replace "table a" with the correct CSS selector for your table links
  html_attr("href") %>%
  unique()  # Ensure unique links
```
```{r}
# Step 2: Create a function to extract the subsequent link from each page
safe_get_subsequent_link <- function(link, retries = 3, sleep_time = 1) {
  full_url <- url_absolute(link, main_url)
  attempt <- 1  # Initialize attempt counter
  
  while (attempt <= retries) {
    # Try to read the HTML and extract the link
    tryCatch({
      message("Attempt ", attempt, " for link: ", full_url)
      
      # Fetch the page with a user-agent and timeout
      page <- read_html(GET(full_url, timeout(30), user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"))
      
      # Extract the link from the subsequent page
      subsequent_link <- page %>%
        html_nodes("li.field__item > a:nth-child(1)") %>%  # Use your CSS selector
        html_attr("href") %>%  # Adjust this if it's not an <a> tag
        unique() %>%
        .[1]  # Assuming you want the first link found, adjust as necessary
      
      # If successful, return the extracted link
      return(subsequent_link)
    }, error = function(e) {
      message("Error in attempt ", attempt, " for link: ", full_url, " - ", e$message)
      
      # Increment the attempt counter and sleep before retrying
      attempt <- attempt + 1
      Sys.sleep(sleep_time)  # Sleep for specified time between retries
    })
  }
  
  # If all retries fail, return NA to indicate the failure
  message("All attempts failed for link: ", full_url)
  return(NA)
}

# Step 2: Apply the retry logic to each link
subsequent_links <- map(links, ~ safe_get_subsequent_link(.x))

#Combine links and subsequent links into a data frame for easier inspection
result <- data.frame(main_page_link = links, subsequent_page_link = subsequent_links)
```

```{r, Download zipped up .txt files from the list of links.}
# Define the root URL
root_url <- "https://www.cms.gov"

# Prepend the root URL to all links in subsequent_links
full_subsequent_links <- paste0(root_url, subsequent_links)
```
```{r}
local_directory <- "C://Users//Nick//Desktop//VA//GENCO//enrollment"

# Function to download the zip files with a timeout setting
download_zip_file_with_timeout <- function(zip_url, save_dir, timeout_secs = 300) {
  if (is.na(zip_url)) {
    message("Skipping NA link")
    return(NULL)
  }
  
  # Define a simple filename based on the basename of the URL, removing query strings
  file_name <- str_extract(basename(zip_url), "[^?]+")
  
  # Define the local file path for the zip file
  zip_path <- file.path(save_dir, file_name)
  
  # Download the file with a timeout using httr::GET and write to a file
  tryCatch({
    response <- GET(zip_url, timeout(timeout_secs), write_disk(zip_path, overwrite = TRUE))
    
    if (response$status_code == 200) {
      message("Downloaded: ", zip_url, " as ", file_name)
    } else {
      message("Failed to download: ", zip_url, " - Status code: ", response$status_code)
    }
  }, error = function(e) {
    message("Error downloading: ", zip_url, " - ", e$message)
  })
  
  return(zip_path)
}

# Create the directory if it does not exist
if (!dir.exists(local_directory)) {
  dir.create(local_directory, recursive = TRUE)
}

# Apply the function to each link and download the files with a timeout
downloaded_files <- map(full_subsequent_links, ~ download_zip_file_with_timeout(.x, local_directory))

```

# Use 7-zip to extract all enrollment numbers by plan files - save to a directory called "enrollment".

```{r}
# Define the path to the folder containing the .csv files
folder_path <- "C://Users//Nick//Desktop//VA//GENCO//enrollment"

# List all .csv files in the folder and subfolders that start with either "Monthly_Report_By_Plan" or "monthly report by plan"
all_csv_files <- list.files(folder_path, 
                            pattern = "^(Monthly_Report_By_Plan|monthly report by plan).*\\.csv$", 
                            full.names = TRUE, 
                            recursive = TRUE)

# Extract dates from the filenames in both YYYY_MM and Dec 2008_12082008 formats
names_df <- data.frame(
  name = basename(all_csv_files)
) %>%
  mutate(
    # Extract date in the format YYYY_MM
    date = case_when(
      # Format YYYY_MM
      str_detect(name, "\\d{4}_\\d{2}") ~ str_extract(name, "\\d{4}_\\d{2}"),
      
      # Format with month name and date like "Dec 2008_12082008"
      str_detect(name, "\\w{3}\\s\\d{4}_\\d{8}") ~ str_extract(name, "\\d{8}"),
      
      # Default NA if no date is found
      TRUE ~ NA_character_
    ),
    
    # Convert extracted date to Date format (YYYY_MM is assumed to be the first day of the month)
    date = case_when(
      str_detect(date, "^\\d{4}_\\d{2}$") ~ ymd(paste0(date, "_01")),
      str_detect(date, "^\\d{8}$") ~ ymd(date),  # Handle exact dates like 12082008
      TRUE ~ NA_Date_
    )
  )

# Function to process each .csv file based on the extracted date
process_file <- function(file_path, date_var) {
  # Print the name of the file being processed
  cat("Processing file:", basename(file_path), "\n")
  
  # Read the .csv file with specified column names
  data <- read_csv(file_path)
  
  # Convert all column names to lowercase for consistency
  names(data) <- tolower(names(data))
  
  # Add the "date" column
  data <- data %>%
    mutate(date = date_var)
  

  
  return(data)
}

# Process each file and combine the results into a single data frame
all_data <- purrr::map2_dfr(all_csv_files, names_df$date, process_file)
```

```{r}
write.csv(all_data, "C://Users//Nick//Desktop//VA//GENCO-Misc//part3-all-enrollment-data-1-7-2025.csv")

```

```{r}
all_data <- read.csv("C://Users//Nick//Desktop//VA//GENCO-Misc//part3-all-enrollment-data-1-7-2025.csv")

```


```{r, Clean Enrollment Data & Create indicator for 6 month period}
enrollment <- data.frame(contract_id = all_data$`contract.number`,
                         plan_id = all_data$`plan.id`,
                         enrollment = all_data$enrollment,
                         partd = all_data$`offers.part.d`,
                         date = as.Date(all_data$date))

enrollment <- enrollment %>% 
  mutate(
    period = case_when(
      month(date) %in% 1:6 ~ as.Date(paste0(year(date), "-06-30")), # Summarize by first 6 months of year and
      month(date) %in% 7:12 ~ as.Date(paste0(year(date), "-12-31")) # last 6 months of the year.
    )
  ) %>% 
  distinct()


#  (1) The privacy laws of HIPAA have been interpreted to prohibit publishing 
#  enrollment data with values of 10 or less. Data rows with enrollment values
#  of 10 or less have been removed from this file. The complete file that includes
#  these removed rows but with blanked out enrollment data is also available for
#  download. 

enrollment$enrollment <- sapply(enrollment$enrollment, function(x) ifelse(x == "*", sample(1:10, 1), x))

enrollment$enrollment <- as.numeric(enrollment$enrollment)

# Drop 51 observations with contract_ids and no plan_id
#enrollment <- enrollment[complete.cases(enrollment), ]
```

```{r, Aggregate at 6-month period and create enrollment weights}
# Group by contract_num, plan_id, and the 6-month period, then summarize enrollment
# * For each plan we have monthly enrollment numbers, we want 6-month chunks to align with the prior auth data.

enrollment_total <- enrollment %>%
  group_by(date) %>%
  summarise(total_enrollment = sum(enrollment, na.rm = TRUE))

enrollment_summary <- left_join(enrollment, enrollment_total, by = "date")

enrollment_summary <- enrollment_summary %>% 
 group_by(contract_id, plan_id, partd, period) %>%
 # average plan enrollment for the 6 month period divided by average  
 mutate(enrollment_weight = enrollment/ total_enrollment) %>% 
 summarize(avg_enrollment_weight = round(mean(enrollment_weight, na.rm = TRUE), 6)) %>% 
  distinct() %>% 
  mutate(date = period) %>% select(-period)

#enrollment_summary <- enrollment_summary %>% group_by(date) %>% mutate(total_enrollment_weight = round(scale(total_enrollment), 3))

#enrollment_summary <- enrollment_summary %>% tidyr::drop_na()
```

```{r, Join Contract-Plan Crosswalk to Enrollment Data}
combined_plan_data$date <- as.Date(combined_plan_data$date)
enrollment_summary$plan_id <- as.factor(as.numeric(enrollment_summary$plan_id))

enrollmentlj <- left_join(combined_plan_data, enrollment_summary, by = c("contract_id", "plan_id", "date"))

enrollmentlj <- enrollmentlj %>% distinct()

```

```{r, Remove leading 000 from the formulary_id from the enrollment data.}
enrollmentlj$formulary_id <- sub("^000", "", enrollmentlj$formulary_id)
```

```{r, Save enrollment data locally}
write.csv(enrollmentlj, "C://Users//Nick//Desktop//VA//GENCO-Misc//part3-enrollment-data-12-3-2024.csv")
```

```{r}
enrollmentlj <- read.csv("C://Users//Nick//Desktop//VA//GENCO-Misc//part3-enrollment-data-12-3-2024.csv")
```


```{r, Load Formulary by App No. per period data}
results <- read.csv("C://Users//Nick//Desktop//VA//GENCO-Misc//part2-data-10-30-2024.csv")
#pd_final <- results
```

```{r, Correct Variable Types in Formulary Data}
chk1$formulary_id <- as.character(chk1$formulary_id)
chk1$date <- as.Date(chk1$date)

results <- chk1 %>% distinct()

```

```{r, Load Drugs@FDA app number dataset}
long_mol <- read.csv("C://Users//Nick//Documents//GENCO//long_mol10-30-2024.csv") # Downloaded from Drugs@FDA. Contact Ravi Gupta for data. 
```

```{r, Manipulate certain rows to get a unique ingredient - app_no combination}
ingredients <- long_mol %>%
  mutate(ingredient = ifelse(appl_no == "NDA214511", 
                                     str_replace(ingredient, " ACETATE", ""), 
                                     ingredient),
         trade_name = ifelse(appl_no == "NDA218347", 
                             str_replace(trade_name, " LQ", ""), 
                             trade_name)) %>% select(ingredient, appl_no) %>% distinct()
```


```{r, Create Enrollment Share Values}
# Create formulary-level enrollment variable.
# Count number of distinct plans and number of plans missing enrollment data.
formulary_enrollmentshare <- enrollmentlj %>% 
  group_by(formulary_id, date) %>% 
  dplyr::summarise(sum_enrollment_share = round(sum(avg_enrollment_weight, na.rm = T), 5),
                   plans = n_distinct(plan_id, contract_id, segment_id),
                   plans_missing_enrollment = sum(is.na(avg_enrollment_weight))) %>% distinct()
```

```{r, Join Enrollment Data to Part D (NDC) dataset}
ndc_level_f <- left_join(results, formulary_enrollmentshare, by = c("formulary_id", "date"))
```

```{r, Split apart application number to two columns}
ndc_level_f$appl_type <- ifelse(grepl("^NDA", ndc_level_f$appl_no), "NDA", 
                      ifelse(grepl("^ANDA", ndc_level_f$appl_no), "ANDA", NA))

# Remove 'NDA' or 'ANDA' from 'app_no'
ndc_level_f$appl_no <- gsub("^(NDA|ANDA)", "", ndc_level_f$appl_no)
```

```{r, Calculate Conversion Period}
appearance <- ndc_level_f %>% filter(appl_type == "ANDA") %>% 
group_by(ingredient, appl_type) %>% 
  arrange(date) %>% 
  summarise(
    unique_formularies_g = n_distinct(formulary_id),
    first_appearance_g = min(date),
    percentile_10_index_g = ceiling(0.10 * unique_formularies_g),
    percentile_50_index_g = ceiling(0.50 * unique_formularies_g),

    date_10_percent_g = nth(date, percentile_10_index_g),
    
    date_50_percent_g = nth(date, percentile_50_index_g),

    blocks_to_10_percent_g = as.integer(difftime(date_10_percent_g, first_appearance_g, units = "days") / 180),
    blocks_to_50_percent_g = as.integer(difftime(date_50_percent_g, first_appearance_g, units = "days") / 180),
    diff = blocks_to_50_percent_g - blocks_to_10_percent_g) %>% select(-appl_type)
```

```{r}
writexl::write_xlsx(appearance, "C://Users//Nick//Desktop//VA//GENCO-Misc//Appearance-3-12-2025.xlsx")
#write.csv(ndc_level_fj, "C://Users//Nick//Desktop//VA//GENCO-Misc//Full Dataset-3-12-2025.csv")
#writexl::write_xlsx(ndc_level_fj_agg, "C://Users//Nick//Desktop//VA//GENCO-Misc//Formulary_Proportion-3-12-2025.xlsx")

```


```{r, Join back to master dataset}

ndc_level_fin <- left_join(ndc_level_f, appearance, "ingredient")


```
```{r, Trim down final dataset}
ndc_level_fin <- ndc_level_fin %>% select(ingredient, appl_no, appl_type, ndc11, date, date_10_percent_g, formulary_id, prior_authorization_yn, sum_enrollment_share)

```
```{r, Create two new variables - pre and post conversion}
ndc_level_fin <- ndc_level_fin %>%
  mutate(
    pre_conversion = date_10_percent_g %m-% years(1), # Date one year before
    post_conversion = date_10_percent_g %m+% years(1)  # Date one year after
  )
colnames(ndc_level_fin)[colnames(ndc_level_fin) == "date_10_percent_g"] <- "conversion_date"

```

```{r}

library(dplyr)
#library(hablar)

# Collapse dataset to ingredient level
ingredient_data <- ndc_level_fin %>%
  group_by(ingredient, ndc11) %>%
  summarise(
    conversion_date = min(s(conversion_date), na.rm = TRUE),
    pre_conversion = min(s(pre_conversion), na.rm = TRUE),
    post_conversion = min(s(post_conversion), na.rm = TRUE),
    earliest = min(date, na.rm = TRUE),
    mid = median(date, na.rm = TRUE),
    most_recent_date = max(date, na.rm = TRUE)) %>% 
  mutate(conversion_date = if_else(is.infinite(conversion_date), NA, conversion_date),
    pre_conversion = if_else(is.infinite(pre_conversion), NA, pre_conversion),
    post_conversion = if_else(is.infinite(post_conversion), NA, post_conversion),
        converted = ifelse(any(!is.na(conversion_date)), 1, 0))

```


```{r}
writexl::write_xlsx(ingredient_data, "C://Users//Nick//Desktop//VA//GENCO-Misc//all_ndcs-2-3-2025.xlsx" )
```

```{r}
test <- ndc_level_fin# %>% filter(!is.na(conversion_date))
  #filter(ingredient == "CLOBAZAM" | ingredient == "ASENAPINE MALEATE" | ingredient == "APIXABAN" | ingredient == "MARAVIROC")
```

```{r}
# Assign NDC based on first appearance per ingredient, taking the lowest NDC in case of ties
new_appearance <- ndc_level_fin %>% 
  group_by(ingredient, formulary_id) %>% 
  arrange(date, ndc11) %>%  # Arrange by date first, then NDC to break ties
  slice(1) %>%  # Select the first occurrence
  distinct(ingredient, date, ndc11, formulary_id) %>% group_by(ingredient, date, ndc11) %>% summarize(unique_formularies = n_distinct(formulary_id))

```

```{r}
library(dplyr)
library(tidyr)

# Aggregate data by date and NDC
transformed_test <- test %>% distinct(ingredient, prior_authorization_yn, ndc11, formulary_id, date, conversion_date) %>% 
  group_by(ingredient, date, ndc11, conversion_date) %>% 
  dplyr::summarise(
    num_nopauth = sum(prior_authorization_yn == 0, na.rm = TRUE),  # Count where pauth_presence = 0
    total_formularies = n_distinct(formulary_id),  # Count total formularies for that NDC and date
    prop_pauth = ifelse(total_formularies > 0, round(num_nopauth / total_formularies, 2), NA) # Compute rounded proportion
  ) %>% ungroup() %>% 
  mutate(
    formatted_value = ifelse(!is.na(prop_pauth),
                             paste0(prop_pauth, " [", num_nopauth, "/", total_formularies, "]"), 
                             NA),
    ndc_short = substr(as.character(ndc11), nchar(as.character(ndc11)) - 6, nchar(as.character(ndc11))) # Extract last 5 digits
  )


transformed_test_tot <- test %>% distinct(ingredient, prior_authorization_yn, formulary_id, date, conversion_date) %>% 
  group_by(ingredient, date, conversion_date) %>%
  dplyr::summarise(
    num_nopauth = sum(prior_authorization_yn == 0, na.rm = TRUE),  # Formularies with at least 1 NDC with pauth = 0.
    total_formularies = n_distinct(formulary_id),  # Total unique formularies for that period. 
    prop_pauth = ifelse(total_formularies > 0, round(num_nopauth / total_formularies, 2), NA) # Compute rounded proportion
  ) %>% ungroup() %>% 
  mutate(ndc = 0,
    formatted_value = ifelse(!is.na(prop_pauth),
                             paste0(prop_pauth, " [", num_nopauth, "/", total_formularies, "]"), 
                             NA), 
    ndc_short = "TOTAL")

final_data <- bind_rows(transformed_test, transformed_test_tot)
final_data <- left_join(final_data, new_appearance, by = c("ingredient", "date", "ndc11"))

```

```{r}
wide_data <- final_data %>%
  select(date, ingredient, ndc11, conversion_date, formatted_value) %>%
  pivot_wider(
    names_from = ndc11,
    values_from = formatted_value,
    names_glue = "ndc11{ndc11}"
  )

# Add Converted column (1 if date is on or after 6/30/2019, else 0)
wide_data <- wide_data %>%
  mutate(Converted = ifelse(date >= conversion_date, 1, 0))
```
```{r}
writexl::write_xlsx(wide_data, "C://Users//Nick//Desktop//VA//GENCO-Misc//clobazam-example-1-29-2025.xlsx" )


```
```{r}
library(ggplot2)
# Create ggplot visualization
final_data2 <- final_data %>% filter(ingredient %in% c("DESVENLAFAXINE SUCCINATE", "VILAZODONE HYDROCHLORIDE", "TOLVAPTAN", "TICAGRELOR
", "TERIFLUNOMIDE")) 
ggplot(final_data2, aes(x = date, y = as.factor(ndc_short))) +
  # Red points for total formularies
  geom_point(aes(size = total_formularies), color = "grey", alpha = 0.75) +
  # Red points for total formularies
  #geom_point(aes(size = unique_formularies), color = "darkgreen", alpha = 0.5) +
  # Blue points for num_pauth (formularies with prior auth)
  geom_text(aes(label = prop_pauth), color = "black", alpha = 1, size = 2) +
  
    geom_vline(
    data = final_data2[!is.na(final_data2$conversion_date), ], 
    aes(xintercept = as.numeric(conversion_date)), 
    linetype = "dashed", 
    color = "red"
  )  + 
  # Labels & theme
  labs(
    title = "NDC-Level Prior Authorization and Formularies Over Time for CLOBAZAM, ASENAPINE MALEATE, and APIXABAN",
    x = "Date",
    y = "NDC (Last 7 Digits) + TOTAL",
    size = "Unique Formularies"
  ) + facet_grid(rows = vars(ingredient), scales = "free_y")
```
```{r}
library(ggplot2)
final_data2 <- final_data %>% filter(ingredient %in% c("DESVENLAFAXINE SUCCINATE", "VILAZODONE HYDROCHLORIDE", "TOLVAPTAN", "TICAGRELOR
", "TERIFLUNOMIDE") & ndc_short == "TOTAL") %>% mutate(conversion = if_else(conversion_date == date, "Yes", "No"))
final_data2$ingredient = with(final_data2, reorder(ingredient, date))
# Create ggplot visualization
plot1 <- ggplot(final_data2, aes(x = date, y = as.factor(ingredient))) +
  # Red points for total formularies
  geom_point(aes(color = conversion), alpha = 0.5, size = 2) +
  # Red points for total formularies
  #geom_point(aes(size = unique_formularies), color = "darkgreen", alpha = 0.5) +
  # Blue points for num_pauth (formularies with prior auth)
  geom_text(aes(label = prop_pauth), color = "black", alpha = 1, size = 2) +
  # Labels & theme
  labs(
    title = "Proportion of Formularies with Prior-auth free access",
    x = "Date",
    y = "Ingredients Converted to Generic",
    color = "Conversion Period",
  ) + scale_color_manual(values = c("grey", "red")) 
```
```{r}
ggsave("Generic Conversion Plot.png", plot1,  height = 11, width = 8)
```
```{r}
library(ggplot2)
final_data2 <- final_data %>% 
  filter(ndc_short == "TOTAL") %>% 
  mutate(conversion = if_else(conversion_date == date, "Yes", "No"))

final_data2$ingredient = with(final_data2, reorder(ingredient, date))

# Create heatmap visualization
plot2 <- ggplot(final_data2, aes(x = date, y = as.factor(ingredient), fill = prop_pauth)) +
  geom_tile(aes(alpha = prop_pauth), show.legend = NA) +  # Use opacity to reflect prop_pauth
  geom_text(aes(label = if_else(conversion == "Yes", "|", "")), color = "red", size = 3) +  # Keep conversion date labels
  # Labels & theme
  labs(
    title = "Prop of Formularies of Molecule Covering PAFree Drug",
    x = "Date",
    y = "Ingredients Converted to Generic",
    fill = "Prop"
  ) +
  scale_fill_gradient(low = "white", high = "blue") +
  scale_alpha(range = c(0.2, 1), guide = "none")  # Remove alpha legend
```
```{r}
ggsave("Generic Conversion Plot - Heat map.png", plot2, height = 11, width = 8)
```
```{r}

# Aggregate data by date and NDC
transformed_test_enrollment_share <- ndc_level_fin %>% distinct(ingredient, prior_authorization_yn, formulary_id, date, conversion_date, sum_enrollment_share) %>% filter(prior_authorization_yn == 0) %>%
  group_by(ingredient, date, conversion_date) %>% 
  dplyr::summarise(
    num_ndcs = n_distinct(formulary_id),  # Count total formularies for that NDC and date
    total_formularies = n_distinct(formulary_id),  # Count total formularies for that NDC and date
    prop_average_monthly_enrollees_paf = sum(sum_enrollment_share)
  ) %>% ungroup()

library(ggplot2)
final_data3 <- transformed_test_enrollment_share %>% 
  mutate(conversion = if_else(conversion_date == date, "Yes", "No"))

final_data3$ingredient = with(final_data3, reorder(ingredient, date))
```
```{r}
# Create heatmap visualization
plot3 <- ggplot(final_data3, aes(x = date, y = as.factor(ingredient), fill = prop_average_monthly_enrollees_paf)) +
  geom_tile(aes(alpha = prop_average_monthly_enrollees_paf), show.legend = NA) +  # Use opacity to reflect prop_pauth
  geom_text(aes(label = if_else(conversion == "Yes", "|", "")), color = "red", size = 3) +  # Keep conversion date labels
  # Labels & theme
  labs(
    title = "Prop All Monthly Enrollees w/ PAFree Drug Covered",
    x = "Date",
    y = "Ingredients Converted to Generic",
    fill = "Prop"
  ) +
  scale_fill_gradient(low = "white", high = "purple4") +
  scale_alpha(range = c(0.2, 1), guide = "none")  # Remove alpha legend

plot3
```
```{r}
ggsave("Generic Conversion Plot 2- Heat map.png", plot3, height = 11, width = 8)
```


```{r}
unique_ingredients <- data.frame(
  ingredient = unique(final_data3$ingredient),
  mol_id = seq_along(unique(final_data3$ingredient))  # Assign numeric IDs
)

## Left join person id back onto data
model_dat <- left_join(final_data3, unique_ingredients, by = "ingredient")


```

```{r, Create Period and Conversion Period Varaible}
model_dat <- model_dat %>%
  mutate(date = as.Date(date),                  # Ensure date is in Date format
         conversion_date = as.Date(conversion_date))  # Ensure conversion_date is in Date format

# Define the start period
start_period <- as.Date("2007-06-30")
```
```{r}
# Calculate periods every six months
model_dat <- mol_level_wide %>%
  mutate(
    period = as.integer((as.numeric(difftime(date, start_period, units = "days")) / 182.5)) + 1,  # Six-month intervals
    conversion_period = ifelse(
      !is.na(conversion_date),
      as.integer((as.numeric(difftime(conversion_date, start_period, units = "days")) / 182.5)) + 1,
      NA_integer_
    )
  ) %>% arrange(ingredient, period)
```



```{r}
library(did)
example_attgt <- att_gt(yname = "prop_average_monthly_enrollees_paf", #outcome
                        tname = "period", #time
                        idname = "mol_id", #molecule 
                        gname = "conversion_period", 
                        data = model_dat,
                        control_group="notyettreated", #includes not-yet converted molecules in control group.
                        allow_unbalanced_panel = TRUE, #don't balance panel with respect to time and id
                        base_period= "varying" # varying base results in an estimate of ATT(g, t) being reported in the period immediately before treatment. 
                                                )

```

```{r}
data <- model_dat %>% select(mol_id, period, conversion_period, prop_average_monthly_enrollees_paf) %>% na.omit()
Dtl <- sapply(-(max(data$period)-1):(max(data$period)-2), function(l) {
    dtl <- 1*( (data$period == data$conversion_period + l) & (data$conversion_period > 0) )
    dtl
})

Dtl <- as.data.frame(Dtl)
cnames1 <- paste0("Dtmin", (max(data$period)-1):1)
colnames(Dtl) <- c(cnames1, paste0("Dt", 0:(max(data$period)-2)))

data <- cbind.data.frame(data, Dtl)
row.names(data) <- NULL

head(data)
```
```{r}
# load plm package
library(plm)

# run event study regression
# normalize effect to be 0 in pre-treatment period
es <- plm(prop_average_monthly_enrollees_paf ~ Dtmin3 + Dtmin2 + Dt0 + Dt1 + Dt2, 
          data = data, model = "within", effect = "twoways",
          index = c("mol_id", "period"))

summary(es)

coefs1 <- coef(es)
ses1 <- sqrt(diag(summary(es)$vcov))
idx.pre <- 1:(max(data$period)-2)
idx.post <- (max(data$period)-1):length(coefs1)
coefs <- c(coefs1[idx.pre], 0, coefs1[idx.post])
ses <- c(ses1[idx.pre], 0, ses1[idx.post])
exposure <- -(max(data$period)-1):(max(data$period)-2)

cmat <- data.frame(coefs=coefs, ses=ses, exposure=exposure)

```
```{r}
library(ggplot2)

ggplot(data = cmat, mapping = aes(y = coefs, x = exposure)) +
  geom_line(linetype = "dashed") +
  geom_point() + 
  geom_errorbar(aes(ymin = (coefs-1.96*ses), ymax = (coefs+1.96*ses)), width = 0.2) +
  ylim(c(-2, 5)) +
  theme_bw()

```

```{r}
es <- aggte(example_attgt, type = "dynamic", na.rm = T)
#group_effects <- aggte(example_attgt, type = "group", na.rm = T)

summary(example_attgt) # The P-value for pre-test of parallel trends assumption is for a Wald pre-test of the parallel trends assumption. Here the parallel trends assumption would not be rejected at conventional significance levels.
summary(es)
```

```{r, Visualize}
#ggdid(example_attgt) #This provides estimates of group-time average treatment effects for all groups in all time periods. Group-time average treatment effects are identified when t >= g (these are post-treatment time periods for each group), but summary reports them even in periods when t < g – these can be used to pre-test for the parallel trends assumption. 
did::(es) #There are many cases where it is convenient to aggregate the group-time average treatment effects into a small number of parameters. 
```

